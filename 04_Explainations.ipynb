{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb94eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if running on colab install facenet-pytorch\n",
    "ON_COLAB = 'google.colab' in str(get_ipython())\n",
    "\n",
    "if ON_COLAB:\n",
    "    !pip install -q facenet-pytorch zennit\n",
    "\n",
    "if ON_COLAB:\n",
    "    BASE_PATH = '/content/drive/MyDrive/xai_faces/'\n",
    "    MODEL_PATH = '/content/drive/MyDrive/xai_faces/models/'\n",
    "else:\n",
    "    BASE_PATH = '../data/'\n",
    "    MODEL_PATH = '../models/'\n",
    "        \n",
    "DARK_UNDERSAMPLED_PATH = BASE_PATH + 'dark_undersampled_cropped' \n",
    "LIGHT_UNDERSAMPLED_PATH = BASE_PATH + 'light_undersampled_cropped' \n",
    "DARK_MODEL_PATH = MODEL_PATH + 'dark_undersampled1.pt'\n",
    "LIGHT_MODEL_PATH = MODEL_PATH + 'light_undersampled1.pt'\n",
    "\n",
    "RANDOM_SEED = 80223"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44f3653",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.nn import Linear\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor, Normalize, Compose, Resize, CenterCrop\n",
    "\n",
    "from facenet_pytorch import InceptionResnetV1\n",
    "\n",
    "from zennit.image import imgify#, imsave\n",
    "from zennit.attribution import Gradient, SmoothGrad\n",
    "from zennit.composites import EpsilonGammaBox, EpsilonPlusFlat, SpecialFirstLayerMapComposite\n",
    "from zennit.torchvision import ResNetCanonizer\n",
    "\n",
    "from zennit.rules import Epsilon, ZPlus, ZBox, Norm, Pass, Flat\n",
    "from zennit.types import Convolution, Activation, AvgPool, BatchNorm, MaxPool, Linear as AnyLinear\n",
    "\n",
    "from xai_helpers import generate_xai_image1, generate_xai_image2, generate_xai_image3, get_image_data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedb0a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_index(dataset, image_path):\n",
    "    for i, (path, target) in enumerate(dataset.imgs):\n",
    "        if path == image_path:\n",
    "            return i\n",
    "    raise ValueError(\"Image path not found in the dataset\")\n",
    "\n",
    "def get_image_data(dataset, index, transform, class_to_idx):\n",
    "    input_image, input_target = dataset.imgs[index]\n",
    "    image = Image.open(input_image)\n",
    "    data = transform(image)[None]\n",
    "    target = torch.eye(len(class_to_idx))[[input_target]]\n",
    "    return input_image, input_target, image, data, target\n",
    "\n",
    "def generate_xai_image(method, model, data, target, noise_level = 0.1, n_iter = 20, symmetric = False, cmap = 'hot'):\n",
    "    if method == 'Gradient':\n",
    "        with Gradient(model = model) as attributor: \n",
    "            output, attribution = attributor(data, target)\n",
    "    elif method == 'SmoothGrad':\n",
    "        with SmoothGrad(noise_level = noise_level, n_iter = n_iter, model = model) as attributor: \n",
    "            output, attribution = attributor(data, target)\n",
    "    ### Layer-wise Relevance Propagation (LRP) with EpsilonPlusFlat\n",
    "    elif method == 'EpsilonPlusFlat':\n",
    "        composite = EpsilonPlusFlat()\n",
    "        with Gradient(model = model, composite = composite) as attributor: \n",
    "            output, attribution = attributor(data, target)\n",
    "    ### LRP with EpsilonGammaBox\n",
    "    elif method == 'EpsilonGammaBox':\n",
    "        # the EpsilonGammaBox composite needs the lowest and highest values, which are here for ImageNet 0. and 1. with a different normalization for each channel\n",
    "        transform_norm = Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "        low, high = transform_norm(torch.tensor([[[[[0.]]] * 3], [[[[1.]]] * 3]])) # create a composite, specifying required arguments\n",
    "        composite = EpsilonGammaBox(low = low, high = high)\n",
    "        with Gradient(model = model, composite = composite) as attributor: \n",
    "            output, attribution = attributor(data, target)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid method name. Choose either 'Gradient', 'SmoothGrad', 'EpsilonPlusFlat' or 'EpsilonGammaBox'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b64e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_norm = Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "\n",
    "# define the full tensor transform\n",
    "transform = Compose([\n",
    "    base_transform,\n",
    "    ToTensor(),\n",
    "    transform_norm,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059e0cc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41380e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac056d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
