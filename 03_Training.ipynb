{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YFNGeCyLdf_8"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/becausejustyn/xai_ppa/blob/main/notebooks/training.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3oCNy03oqM-L"
      },
      "outputs": [],
      "source": [
        "# if running on colab install facenet-pytorch\n",
        "ON_COLAB = 'google.colab' in str(get_ipython())\n",
        "\n",
        "if ON_COLAB:\n",
        "    !pip install -q facenet-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_34AWSon7IO",
        "outputId": "2be22895-cf43-4558-b3d5-f1ae7a0ab075"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Google Drive is already mounted.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# if running on colab, check if drive is mounted\n",
        "try:\n",
        "    with open('/content/drive/My Drive/test.txt') as f:\n",
        "        print('Google Drive is already mounted.')\n",
        "except FileNotFoundError:\n",
        "    drive.mount('/content/drive')\n",
        "    print('Google Drive has been mounted.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "f3szcyipn1Ht"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "#import json\n",
        "#import pickle\n",
        "#import shutil\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "#from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.utils.tensorboard.writer import SummaryWriter\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler, Dataset\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import Resize\n",
        "\n",
        "from facenet_pytorch import MTCNN, InceptionResnetV1, fixed_image_standardization, training\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pd.set_option('display.max_rows', 10)\n",
        "pd.set_option('display.max_columns', 20)\n",
        "pd.set_option('display.expand_frame_repr', False)\n",
        "pd.set_option('max_colwidth', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYv1gLten1BZ",
        "outputId": "3401f961-0f34-4a8b-ea3a-34f224bbb409"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on Google Colab\n",
            "Batch Size: 128\n",
            "Workers: 2\n",
            "Device: cuda:0\n"
          ]
        }
      ],
      "source": [
        "RANDOM_SEED = 310123\n",
        "BATCH_SIZE = 128 if torch.cuda.is_available() else 64\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "EPOCHS = 10\n",
        "LEARNING_RATE = 1e-3\n",
        "\n",
        "WORKERS = 2 if torch.cuda.is_available() else int(os.cpu_count() / 2) \n",
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "if ON_COLAB:\n",
        "\tBASE_PATH = '/content/drive/MyDrive/xai_faces/'\n",
        "else:\n",
        "\tBASE_PATH = '../data/'\n",
        "\n",
        "DARK_UNDERSAMPLED_PATH = BASE_PATH + 'dark_undersampled_cropped' \n",
        "LIGHT_UNDERSAMPLED_PATH = BASE_PATH + 'light_undersampled_cropped' \n",
        "\n",
        "print(f'Batch Size: {BATCH_SIZE}')\n",
        "print(f'Workers: {WORKERS}')\n",
        "print(f'Device: {DEVICE}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SJHdRRLcwE9W"
      },
      "source": [
        "## Dark Undersampled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "b-9-Q1Nvn020"
      },
      "outputs": [],
      "source": [
        "transform1 = transforms.Compose([\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "dataset = ImageFolder(DARK_UNDERSAMPLED_PATH, transform = transform1)\n",
        "\n",
        "# MODEL / resnet\n",
        "MODEL = InceptionResnetV1(\n",
        "    classify = True,\n",
        "    pretrained = 'vggface2',\n",
        "    num_classes = len(dataset.class_to_idx) \n",
        ").to(DEVICE)\n",
        "\n",
        "OPTIMISER = optim.Adam(MODEL.parameters(), lr = LEARNING_RATE)\n",
        "SCHEDULER = MultiStepLR(OPTIMISER, [5, 10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQXOpds8sbkC",
        "outputId": "27e93378-ca9f-43a0-ef15-7160166554de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on Google Colab\n"
          ]
        }
      ],
      "source": [
        "# create stratified training split\n",
        "\n",
        "DARK_DF = pd.read_csv(BASE_PATH + 'dark_undersampled.csv')\n",
        "LIGHT_DF = pd.read_csv(BASE_PATH + 'light_undersampled.csv')\n",
        "\n",
        "DARK_DF = DARK_DF.assign(\n",
        "    image_path_full = lambda x: BASE_PATH + 'dark_undersampled_cropped/' + x['human_id'].astype(str) + '/' + x['render_id'].astype(str) + '.cam_default.f_1.rgb.png',\n",
        ")\n",
        "\n",
        "# Group the dataframe by the label\n",
        "grouped_df = DARK_DF.groupby('skin_labels')\n",
        "\n",
        "# Calculate the number of instances to sample from each group\n",
        "group_counts = grouped_df['image_path_full'].count()\n",
        "sample_counts = (group_counts * 0.8).astype(int)\n",
        "\n",
        "# Create a list to store the train and validation dataframes\n",
        "train_dfs = []\n",
        "val_dfs = []\n",
        "\n",
        "# Loop through each group and split it into training and validation sets\n",
        "for name, group in grouped_df:\n",
        "    group_sample = group.sample(min(len(group), group_counts[name]))\n",
        "    train_group, val_group = train_test_split(group_sample, test_size = 0.2, random_state = RANDOM_SEED)\n",
        "    train_dfs.append(train_group)\n",
        "    val_dfs.append(val_group)\n",
        "\n",
        "# Concatenate the training and validation dataframes\n",
        "train_df = pd.concat(train_dfs, ignore_index = True) # light: 0.598465  dark: 0.401535\n",
        "val_df = pd.concat(val_dfs, ignore_index = True) # light: 0.598465  dark: 0.401535"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IIc_QNytn0xd"
      },
      "outputs": [],
      "source": [
        "# Create a list of indices for train and validation datasets\n",
        "train_indices = [i for i, (path, label) in enumerate(dataset.samples) if path in train_df['image_path_full'].tolist()]\n",
        "val_indices = [i for i, (path, label) in enumerate(dataset.samples) if path in val_df['image_path_full'].tolist()]\n",
        "\n",
        "# Use SubsetRandomSampler to specify the indices for the train and validation splits\n",
        "\n",
        "# Use DataLoader to load the data in batches\n",
        "train_loader = DataLoader(\n",
        "    dataset, \n",
        "    num_workers = WORKERS, batch_size = BATCH_SIZE,\n",
        "    sampler = SubsetRandomSampler(train_indices), shuffle = False)\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    dataset, \n",
        "    num_workers = WORKERS, batch_size = BATCH_SIZE,\n",
        "    sampler = SubsetRandomSampler(val_indices), shuffle = False)\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "metrics = {'acc': training.accuracy}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYgRyJBxn0tJ",
        "outputId": "930b7eed-4b00-4c53-c7f4-e0654799568e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid |     3/3    | loss:    4.2860 | acc:    0.0106   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "Train |    12/12   | loss:    3.4125 | acc:    0.1726   \n",
            "Valid |     2/3    | loss:    9.2703 | acc:    0.0430   "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 1/10 [08:34<1:17:11, 514.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\rValid |     3/3    | loss:    9.4412 | acc:    0.0371   \n",
            "Epoch 2/10\n",
            "Train |    12/12   | loss:    1.7189 | acc:    0.5905   \n",
            "Valid |     2/3    | loss:    2.7013 | acc:    0.2539   "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 2/10 [08:54<29:48, 223.62s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\rValid |     3/3    | loss:    2.6693 | acc:    0.2766   \n",
            "Epoch 3/10\n",
            "Train |    12/12   | loss:    0.7201 | acc:    0.8811   \n",
            "Valid |     2/3    | loss:    1.8692 | acc:    0.4844   "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 3/10 [09:12<15:08, 129.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\rValid |     3/3    | loss:    1.9134 | acc:    0.4924   \n",
            "Epoch 4/10\n",
            "Train |    12/12   | loss:    0.2765 | acc:    0.9706   \n",
            "Valid |     2/3    | loss:    0.9853 | acc:    0.7656   "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 4/10 [09:30<08:33, 85.57s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\rValid |     3/3    | loss:    0.9341 | acc:    0.7760   \n",
            "Epoch 5/10\n",
            "Train |    12/12   | loss:    0.1304 | acc:    0.9906   \n",
            "Valid |     2/3    | loss:    0.8354 | acc:    0.7930   "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 5/10 [09:49<05:07, 61.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\rValid |     3/3    | loss:    0.8416 | acc:    0.7914   \n",
            "Epoch 6/10\n",
            "Train |    12/12   | loss:    0.0532 | acc:    0.9993   \n",
            "Valid |     2/3    | loss:    0.6433 | acc:    0.8555   "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 6/10 [10:07<03:06, 46.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\rValid |     3/3    | loss:    0.6053 | acc:    0.8669   \n",
            "Epoch 7/10\n",
            "Train |    12/12   | loss:    0.0354 | acc:    1.0000   \n",
            "Valid |     2/3    | loss:    0.5064 | acc:    0.8750   "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 7/10 [10:25<01:52, 37.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\rValid |     3/3    | loss:    0.5350 | acc:    0.8771   \n",
            "Epoch 8/10\n",
            "Train |    12/12   | loss:    0.0270 | acc:    1.0000   \n",
            "Valid |     2/3    | loss:    0.4067 | acc:    0.9219   "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 8/10 [10:44<01:02, 31.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\rValid |     3/3    | loss:    0.5075 | acc:    0.8942   \n",
            "Epoch 9/10\n",
            "Train |    12/12   | loss:    0.0236 | acc:    1.0000   \n",
            "Valid |     2/3    | loss:    0.4471 | acc:    0.9062   "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 9/10 [11:01<00:27, 27.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\rValid |     3/3    | loss:    0.4852 | acc:    0.9036   \n",
            "Epoch 10/10\n",
            "Train |    12/12   | loss:    0.0195 | acc:    1.0000   \n",
            "Valid |     2/3    | loss:    0.4647 | acc:    0.9062   "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [11:19<00:00, 67.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\rValid |     3/3    | loss:    0.4724 | acc:    0.9036   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "writer = SummaryWriter()\n",
        "writer.iteration = 0\n",
        "writer.interval = 10\n",
        "\n",
        "MODEL.eval()\n",
        "\n",
        "training.pass_epoch(\n",
        "    MODEL, loss_fn, val_loader, \n",
        "    batch_metrics = metrics, show_running = True, \n",
        "    device = DEVICE, writer = writer)\n",
        "\n",
        "for epoch in tqdm(range(EPOCHS)):\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  MODEL.train()\n",
        "  training.pass_epoch(\n",
        "      MODEL, loss_fn, train_loader, \n",
        "      OPTIMISER, SCHEDULER, \n",
        "      batch_metrics = metrics, show_running = True, \n",
        "      device = DEVICE, writer = writer)\n",
        "  MODEL.eval()\n",
        "  training.pass_epoch(\n",
        "      MODEL, loss_fn, val_loader, \n",
        "      batch_metrics = metrics, show_running = True, \n",
        "      device = DEVICE, writer = writer)\n",
        "\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "T5Cr7GZKn0oP"
      },
      "outputs": [],
      "source": [
        "MODEL_PATH = BASE_PATH + 'models/dark_undersampled1.pt'\n",
        "#PATH = '/content/drive/MyDrive/xai_faces/models/dark_undersampled1.pt'\n",
        "STATE_DICT = MODEL.state_dict()\n",
        "\n",
        "checkpoint = {\n",
        "    'STATE_DICT': STATE_DICT,\n",
        "    'TRANSFORMATION': transform1,\n",
        "    'RANDOM_SEED': RANDOM_SEED,\n",
        "    'BATCH_SIZE': BATCH_SIZE,\n",
        "    'EPOCHS': EPOCHS,\n",
        "    'LEARNING_RATE': LEARNING_RATE,\n",
        "    'WORKERS': WORKERS,\n",
        "    'DEVICE': DEVICE\n",
        "}\n",
        "\n",
        "torch.save(checkpoint, MODEL_PATH)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XhD93B7wwbpC"
      },
      "source": [
        "## Light Undersampled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Q6AdqkGT2Wv5"
      },
      "outputs": [],
      "source": [
        "# so I do not need to restart the runtime\n",
        "del MODEL, writer, train_loader, val_loader, dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "r4FwnIrjn0f3"
      },
      "outputs": [],
      "source": [
        "# load the dataset without a transformation \n",
        "dataset = ImageFolder(LIGHT_UNDERSAMPLED_PATH, transform = transform1)\n",
        "\n",
        "# MODEL / resnet\n",
        "MODEL = InceptionResnetV1(\n",
        "    classify = True,\n",
        "    pretrained = 'vggface2',\n",
        "    num_classes = len(dataset.class_to_idx) \n",
        ").to(DEVICE)\n",
        "\n",
        "OPTIMISER = optim.Adam(MODEL.parameters(), lr = LEARNING_RATE)\n",
        "SCHEDULER = MultiStepLR(OPTIMISER, [5, 10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "OmZ9EYXhn0Y0"
      },
      "outputs": [],
      "source": [
        "# create stratified training split\n",
        "\n",
        "LIGHT_DF = LIGHT_DF.assign(\n",
        "    image_path_full = lambda x: BASE_PATH + 'light_undersampled_cropped/' + x['human_id'].astype(str) + '/' + x['render_id'].astype(str) + '.cam_default.f_1.rgb.png',\n",
        ")\n",
        "\n",
        "# Group the dataframe by the label\n",
        "grouped_df = LIGHT_DF.groupby('skin_labels')\n",
        "\n",
        "# Calculate the number of instances to sample from each group\n",
        "group_counts = grouped_df['image_path_full'].count()\n",
        "sample_counts = (group_counts * 0.8).astype(int)\n",
        "\n",
        "# Create a list to store the train and validation dataframes\n",
        "train_dfs = []\n",
        "val_dfs = []\n",
        "\n",
        "# Loop through each group and split it into training and validation sets\n",
        "for name, group in grouped_df:\n",
        "    group_sample = group.sample(min(len(group), group_counts[name]))\n",
        "    train_group, val_group = train_test_split(group_sample, test_size = 0.2, random_state = RANDOM_SEED)\n",
        "    train_dfs.append(train_group)\n",
        "    val_dfs.append(val_group)\n",
        "\n",
        "# Concatenate the training and validation dataframes\n",
        "train_df = pd.concat(train_dfs, ignore_index = True) # light: 0.598465  dark: 0.401535\n",
        "val_df = pd.concat(val_dfs, ignore_index = True) # light: 0.598465  dark: 0.401535\n",
        "\n",
        "# Create a list of indices for train and validation datasets\n",
        "train_indices = [i for i, (path, label) in enumerate(dataset.samples) if path in train_df['image_path_full'].tolist()]\n",
        "val_indices = [i for i, (path, label) in enumerate(dataset.samples) if path in val_df['image_path_full'].tolist()]\n",
        "\n",
        "# Use SubsetRandomSampler to specify the indices for the train and validation splits\n",
        "\n",
        "# Use DataLoader to load the data in batches\n",
        "train_loader = DataLoader(\n",
        "    dataset, \n",
        "    num_workers = WORKERS, batch_size = BATCH_SIZE,\n",
        "    sampler = SubsetRandomSampler(train_indices), shuffle = False)\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    dataset, \n",
        "    num_workers = WORKERS, batch_size = BATCH_SIZE,\n",
        "    sampler = SubsetRandomSampler(val_indices), shuffle = False)\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "metrics = {'acc': training.accuracy}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sU_MjcUen0UU",
        "outputId": "293808e9-0ffd-4afb-af9b-c2ed56288cad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid |     3/3    | loss:    4.3050 | acc:    0.0057   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "Train |    12/12   | loss:    3.5581 | acc:    0.1258   \n",
            "Valid |     2/3    | loss:   12.3821 | acc:    0.0469   "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 1/10 [09:33<1:26:05, 573.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\rValid |     3/3    | loss:   13.0821 | acc:    0.0312   \n",
            "Epoch 2/10\n",
            "Train |    12/12   | loss:    1.9645 | acc:    0.5153   \n",
            "Valid |     2/3    | loss:    3.2770 | acc:    0.1445   "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 2/10 [09:52<32:55, 246.95s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\rValid |     3/3    | loss:    3.2681 | acc:    0.1498   \n",
            "Epoch 3/10\n",
            "Train |    12/12   | loss:    1.0584 | acc:    0.7624   \n",
            "Valid |     2/3    | loss:    2.5067 | acc:    0.3164   "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 3/10 [10:10<16:39, 142.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\rValid |     3/3    | loss:    2.5097 | acc:    0.3021   \n",
            "Epoch 4/10\n",
            "Train |    12/12   | loss:    0.5408 | acc:    0.9026   \n",
            "Valid |     2/3    | loss:    1.6707 | acc:    0.5430   "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 4/10 [10:27<09:18, 93.16s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\rValid |     3/3    | loss:    1.6627 | acc:    0.5507   \n",
            "Epoch 5/10\n",
            "Train |    12/12   | loss:    0.2557 | acc:    0.9638   \n",
            "Valid |     2/3    | loss:    1.2124 | acc:    0.6836   "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 5/10 [10:45<05:28, 65.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\rValid |     3/3    | loss:    1.2257 | acc:    0.6790   \n",
            "Epoch 6/10\n",
            "Train |    12/12   | loss:    0.1066 | acc:    0.9967   \n",
            "Valid |     2/3    | loss:    0.5746 | acc:    0.8594   "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 6/10 [11:03<03:17, 49.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\rValid |     3/3    | loss:    0.6334 | acc:    0.8559   \n",
            "Epoch 7/10\n",
            "Train |    12/12   | loss:    0.0767 | acc:    0.9980   \n",
            "Valid |     2/3    | loss:    0.5632 | acc:    0.8867   "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 7/10 [11:21<01:58, 39.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\rValid |     3/3    | loss:    0.5360 | acc:    0.8836   \n",
            "Epoch 8/10\n",
            "Train |    12/12   | loss:    0.0510 | acc:    0.9987   \n",
            "Valid |     2/3    | loss:    0.4973 | acc:    0.8789   "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 8/10 [11:39<01:04, 32.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\rValid |     3/3    | loss:    0.5220 | acc:    0.8847   \n",
            "Epoch 9/10\n",
            "Train |    12/12   | loss:    0.0429 | acc:    0.9993   \n",
            "Valid |     2/3    | loss:    0.5308 | acc:    0.8867   "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 9/10 [11:56<00:27, 27.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\rValid |     3/3    | loss:    0.4826 | acc:    0.9025   \n",
            "Epoch 10/10\n",
            "Train |    12/12   | loss:    0.0354 | acc:    1.0000   \n",
            "Valid |     2/3    | loss:    0.4547 | acc:    0.8945   "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [12:14<00:00, 73.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\rValid |     3/3    | loss:    0.4719 | acc:    0.9014   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "writer = SummaryWriter()\n",
        "writer.iteration = 0\n",
        "writer.interval = 10\n",
        "\n",
        "MODEL.eval()\n",
        "\n",
        "training.pass_epoch(\n",
        "    MODEL, loss_fn, val_loader, \n",
        "    batch_metrics = metrics, show_running = True, \n",
        "    device = DEVICE, writer = writer)\n",
        "\n",
        "for epoch in tqdm(range(EPOCHS)):\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  MODEL.train()\n",
        "  training.pass_epoch(\n",
        "      MODEL, loss_fn, train_loader, \n",
        "      OPTIMISER, SCHEDULER, \n",
        "      batch_metrics = metrics, show_running = True, \n",
        "      device = DEVICE, writer = writer)\n",
        "  MODEL.eval()\n",
        "  training.pass_epoch(\n",
        "      MODEL, loss_fn, val_loader, \n",
        "      batch_metrics = metrics, show_running = True, \n",
        "      device = DEVICE, writer = writer)\n",
        "\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Q2NZFTxgxDds"
      },
      "outputs": [],
      "source": [
        "MODEL_PATH = BASE_PATH + 'models/light_undersampled1.pt'\n",
        "#PATH = '/content/drive/MyDrive/xai_faces/models/light_undersampled1.pt'\n",
        "STATE_DICT = MODEL.state_dict()\n",
        "\n",
        "checkpoint = {\n",
        "    'STATE_DICT': STATE_DICT,\n",
        "    'TRANSFORMATION': transform1,\n",
        "    'RANDOM_SEED': RANDOM_SEED,\n",
        "    'BATCH_SIZE': BATCH_SIZE,\n",
        "    'EPOCHS': EPOCHS,\n",
        "    'LEARNING_RATE': LEARNING_RATE,\n",
        "    'WORKERS': WORKERS,\n",
        "    'DEVICE': DEVICE\n",
        "}\n",
        "\n",
        "torch.save(checkpoint, MODEL_PATH)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bSrqVmnpciH9"
      },
      "source": [
        "```python\n",
        "checkpoint = torch.load(PATH)\n",
        "MODEL.load_state_dict(checkpoint['STATE_DICT'])\n",
        "\n",
        "RANDOM_SEED = checkpoint['RANDOM_SEED']\n",
        "BATCH_SIZE = checkpoint['BATCH_SIZE']\n",
        "EPOCHS = checkpoint['EPOCHS']\n",
        "LEARNING_RATE = checkpoint['LEARNING_RATE']\n",
        "WORKERS = checkpoint['WORKERS']\n",
        "DEVICE = checkpoint['DEVICE']\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "xai_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "0b3ddb784223393a36a60b90c018e23881489e0e14d1a418ff8277d4e1a929d5"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
