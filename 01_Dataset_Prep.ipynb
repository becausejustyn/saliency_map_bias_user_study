{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdd575e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('max_colwidth', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "RANDOM_SEED = 310123\n",
    "N_TOTAL = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12344098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move the jsonl file out of the diverse_human_faces folder\n",
    "FILE_PATH = 'data/diverse_human_faces/metadata.jsonl'\n",
    "DEST_PATH = 'data/metadata.jsonl'\n",
    "\n",
    "shutil.move(FILE_PATH, DEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19411401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for some reason, python does not unnest the JSONL file correctly, so here is a script to have it done in R\n",
    "# it will return metadata.parquet and metadata.csv\n",
    "# then move it to the data directory\n",
    "!Rscript ../src/json_convert.R data/metadata.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fe04b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_path(human_id: int, render_id: int):\n",
    "    return f'{human_id:.0f}/{render_id:.0f}.cam_default.f_1.rgb.png' \n",
    "\n",
    "def get_full_image_path(folder, human_id: int, render_id: int):\n",
    "    return f'{folder}/{human_id:.0f}/{render_id:.0f}.cam_default.f_1.rgb.png' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf73ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using parquet to speed up the loading process\n",
    "# you can do this straight with pandas, but it is slower\n",
    "df = pq.read_table('../data/metadata.parquet').to_pandas()\n",
    "\n",
    "# df.filter(like = 'id').columns\n",
    "# render_id is the same as the folder number I created, eg. render_id 0 == file_0\n",
    "# might be worthwhile to add .zfill() to the render_id column/folder_name\n",
    "\n",
    "human_info = df.rename(columns = {\n",
    "    'scene.identity_metadata.id': 'human_id', \n",
    "    'scene.identity_metadata.sex' : 'sex', \n",
    "    'scene.identity_metadata.age' : 'age',\n",
    "    'scene.identity_metadata.ethnicity': 'ethnicity',\n",
    "    'scene.facial_attributes.head_turn.yaw' : 'yaw',\n",
    "    'scene.facial_attributes.head_turn.roll' : 'roll',\n",
    "    'scene.facial_attributes.head_turn.pitch' : 'pitch',\n",
    "    'scene.identity_metadata.skin_tone' : 'skin_tone',\n",
    "    }, inplace = False).assign(\n",
    "        sex = lambda x: np.where(x['sex'] == 'female', 1, 0),\n",
    "    )[[\n",
    "        'human_id', 'render_id', 'task_id', 'sex', 'age', 'ethnicity', 'yaw', 'roll', 'pitch', 'skin_tone'\n",
    "    ]]\n",
    "\n",
    "# get list of column names to change to float\n",
    "# cols_to_change = human_info.filter(regex = '(^(?!.*_id))').columns.tolist()\n",
    "cols_to_change = [col for col in human_info.columns.tolist() if col not in ['ethnicity', 'task_id', 'render_id']]\n",
    "human_info[cols_to_change] = human_info[cols_to_change].astype(float)\n",
    "\n",
    "human_info = human_info.assign(\n",
    "    # make an int type for the human_id\n",
    "    human_id = lambda x: x['human_id'].astype(int),\n",
    "    # if you only want 3 directions -> lambda x: pd.cut(x['yaw'], bins = [-15, -5, 5, 15], labels = ['left', 'middle', 'right']),\n",
    "    # human_info['yaw'].apply(lambda x: 'left' if x < -5 else ('middle' if -5 <= x <= 5 else 'right'))\n",
    "    yaw_direction = lambda x: pd.cut(x['yaw'], bins = [-15, -7, -4, 4, 7, 15], labels = ['left', 'vacant_left', 'middle', 'vacant_right', 'right']),\n",
    "    # if you want to round to nearest 0.5 instead, use np.round(x['skin_tone'] * 2) / 2\n",
    "    # ceil rounds up, which is what we want since values include 0.74854187 and there is no 0 for this. Similarly, the highest is 5.66467382, which will round to 6 (highest)\n",
    "    skin_tone_rounded = lambda x: np.ceil(x['skin_tone']),\n",
    "    # for this, just attempt light = 1 and 2, dark = 4, 5, 6\n",
    "    skin_labels = lambda x: np.where(x['skin_tone_rounded'] <= 2., 'light', np.where(x['skin_tone_rounded'] >= 4., 'dark', 'misc')),\n",
    "    full_image_path = lambda x: x.apply(lambda y: get_full_image_path(folder = 'data/diverse_human_faces', human_id = int(y['human_id']), render_id = y['render_id']), axis = 1),\n",
    "    image_path = lambda x: x.apply(lambda y: get_image_path(human_id = int(y['human_id']), render_id = y['render_id']), axis = 1),\n",
    ")\n",
    "\n",
    "# save csv and parquet\n",
    "human_info.to_csv('../data/human_info.csv', index = False)\n",
    "pq.write_table(pa.Table.from_pandas(human_info), '../data/human_info.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fc3890",
   "metadata": {},
   "source": [
    "The current layout of `data/diverse_human_faces/` has 70,000 files. Adding folders for the `human_id` to meet the requirements for `torchvision`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312f77fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pq.read_table('../data/human_info.parquet').to_pandas()\n",
    "\n",
    "CURRENT_DIR = os.getcwd().split('/')[-1]\n",
    "PATH = '../data/diverse_human_faces'\n",
    "FOLDER_VALUES_N = np.vectorize(lambda x: int(re.search(r'^(\\d+)', x).group(1)) if re.search(r'^(\\d+)', x) else -1)\n",
    "\n",
    "# sorting the folders by the number in the folder name \n",
    "DIR_FILES = np.array([f for f in os.listdir(PATH) if f != '.DS_Store' and f != 'metadata.jsonl'])\n",
    "DIR_FILES = DIR_FILES[np.argsort(FOLDER_VALUES_N(DIR_FILES))]\n",
    "\n",
    "CURRENT_PATH = '../data/diverse_human_faces'\n",
    "NEW_PATH = '../data/faces_sorted'\n",
    "\n",
    "# create columns for the filenames of the images and jsons\n",
    "df = df[['human_id', 'render_id']].assign(\n",
    "    image_name = lambda x: x['render_id'].astype(str) + '.cam_default.f_1.rgb.png',\n",
    "    json_name = lambda x: x['render_id'].astype(str) + '.cam_default.f_1.info.json'\n",
    ")\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    human_id = str(row['human_id'])\n",
    "    render_id = str(row['render_id'])\n",
    "    image_name = row['image_name']\n",
    "    json_name = row['json_name']\n",
    "    \n",
    "    # create the folder for each human_id\n",
    "    if not os.path.exists(os.path.join(NEW_PATH, human_id)): \n",
    "        # e.g. # data/faces_sorted/325\n",
    "        os.makedirs(os.path.join(NEW_PATH, human_id), exist_ok = True)\n",
    "    \n",
    "    # move the files to the corresponding human_id folder\n",
    "    # from      data/diverse_human_faces/0.cam_default.f_1.rgb.png\n",
    "    # to        data/faces_sorted/325/0.cam_default.f_1.rgb.png  \n",
    "    os.rename(os.path.join(CURRENT_PATH, image_name), os.path.join(NEW_PATH, human_id, image_name)) \n",
    "    os.rename(os.path.join(CURRENT_PATH, json_name), os.path.join(NEW_PATH, human_id, json_name))\n",
    "\n",
    "# checking that it worked as planned. each human_id folder should have 100 images and 100 jsons (200 files total)\n",
    "\n",
    "count = 0\n",
    "\n",
    "for folder in os.listdir(NEW_PATH):\n",
    "    folder_path = os.path.join(NEW_PATH, folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        files = os.listdir(folder_path)\n",
    "        if len(files) != 200:\n",
    "            print(f\"Folder '{folder}' does not have 200 files. It has {len(files)} files.\")\n",
    "        else:\n",
    "            count += 1\n",
    "\n",
    "print(f\"{count} folders have 200 files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d28272",
   "metadata": {},
   "source": [
    "Removing `human_id` where the `skin_tone` == 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71015475",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pq.read_table('../data/human_info.parquet').to_pandas()\n",
    "# now 5422 rows\n",
    "df = df.query('skin_labels != \"misc\" & yaw_direction != \"vacant\"').reset_index(drop = True).assign(\n",
    "    image_path = lambda x: '../data/' + x['image_path']\n",
    ")\n",
    "\n",
    "CURRENT_PATH = '../data/diverse_human_faces'\n",
    "NEW_PATH = '../data/faces_sorted'\n",
    "\n",
    "# create human_id folders in new directory\n",
    "for idx in df['human_id'].unique():\n",
    "    os.makedirs(os.path.join(NEW_PATH, str(idx)), exist_ok = True)\n",
    "\n",
    "for index, row in tqdm(df.iterrows(), total = len(df)):\n",
    "\n",
    "    # image_path             ../data/diverse_human_faces/325/0.cam_default.f_1.rgb.png\n",
    "    image_path = row['image_path']\n",
    "    # image_dest             ../data/faces_sorted/325/0.cam_default.f_1.rgb.png\n",
    "    image_dest = image_path.replace(CURRENT_PATH, NEW_PATH)\n",
    "    shutil.copy2(image_path, image_dest)\n",
    "\n",
    "df.to_csv('../data/full_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94999167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking that the count from df matches the directories \n",
    "files_list = []\n",
    "\n",
    "for folder in os.listdir(NEW_PATH):\n",
    "    folder_path = os.path.join(NEW_PATH, folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        for file in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            files_list.append(os.path.join(folder_path, file))\n",
    "\n",
    "print(f\"Found {len(files_list)} images in {len(os.listdir(NEW_PATH))} human_id.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229471ec",
   "metadata": {},
   "source": [
    "Creating aggregated datasets\n",
    "\n",
    "Proportion of `skin_tone` is the same for both groups, but only use images looking straight for the undersampled group. Hhere you are using straight as the only position for the undersampled group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126cc4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pq.read_table('../data/human_info.parquet').to_pandas()\n",
    "\n",
    "df_summary = (df\n",
    "    .groupby('human_id')\n",
    "    .size()\n",
    "    .reset_index()\n",
    "    .rename(columns = {0: 'n'})\n",
    "    .merge(\n",
    "        df.drop_duplicates(subset = ['human_id'])[['human_id', 'skin_labels']].reset_index(drop = True)\n",
    "))\n",
    "\n",
    "df_summary.sort_values('n', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36977d55",
   "metadata": {},
   "source": [
    "Creating the biased datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34883491",
   "metadata": {},
   "outputs": [],
   "source": [
    "dark_undersampled_df = pd.concat([\n",
    "    # all values where skin_labels == \"dark\" and yaw_direction == \"middle\" (785, 14)\n",
    "    # 473 male, 312 female\n",
    "    df.query('skin_labels == \"dark\" and yaw_direction == \"middle\"'),\n",
    "    # sample light skin faces, across the three possible yaw_directions (1170, 14)\n",
    "    # 450 male, 720 female\n",
    "    df.query('skin_labels == \"light\"').groupby('human_id').sample(n = 30, replace = False, random_state = RANDOM_SEED)\n",
    "]).reset_index(drop = True)\n",
    "\n",
    "dark_undersampled_df.to_csv('data/dark_undersampled.csv', index = False)\n",
    "\n",
    "light_undersampled_df = pd.concat([\n",
    "    # all values where skin_labels == \"dark\" and yaw_direction == \"middle\" (1012, 14)\n",
    "    # 620 male, 393 female\n",
    "    df.query('skin_labels == \"light\" and yaw_direction == \"middle\"'),\n",
    "    # sample light skin faces, across the three possible yaw_directions (870, 14)\n",
    "    # 540 male, 330 female\n",
    "    df.query('skin_labels == \"dark\"').groupby('human_id').sample(n = 30, replace = False, random_state = RANDOM_SEED)\n",
    "]).reset_index(drop = True)\n",
    "\n",
    "light_undersampled_df.to_csv('data/light_undersampled.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9c8cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ../data/dark_undersampled ../data/light_undersampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3136949a",
   "metadata": {},
   "source": [
    "Create the Dark Undersampled Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd1661a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dark_undersampled_df = pd.read_csv('data/dark_undersampled.csv')\n",
    "\n",
    "dark_undersampled_df = dark_undersampled_df.assign(\n",
    "    image_path_full = lambda x: 'data/diverse_human_faces/' + x['human_id'].astype(str) + '/' + x['render_id'].astype(str) + '.cam_default.f_1.rgb.png',\n",
    "    json_path_full = lambda x: 'data/diverse_human_faces/' + x['human_id'].astype(str) + '/' + x['render_id'].astype(str) + '.cam_default.f_1.info.json'\n",
    ")\n",
    "\n",
    "CURRENT_PATH = \"data/diverse_human_faces\"\n",
    "DARK_PATH = \"data/dark_undersampled\"\n",
    "\n",
    "for index, row in dark_undersampled_df.iterrows():\n",
    "\n",
    "    # create human_id folders in dark_undersampled\n",
    "    for idx in dark_undersampled_df['human_id'].unique():\n",
    "        os.makedirs(os.path.join(DARK_PATH, str(idx)), exist_ok = True)\n",
    "\n",
    "    # image_path             data/diverse_human_faces/110/101.cam_default.f_1.rgb.png\n",
    "    image_path = row['image_path_full']\n",
    "    # image_dest           data/dark_undersampled/110/101.cam_default.f_1.rgb.png   \n",
    "    image_dest = image_path.replace(CURRENT_PATH, DARK_PATH)\n",
    "    # image_dest.split('/')[-2], e.g. 110\n",
    "    shutil.copy2(image_path, image_dest)\n",
    "\n",
    "    # json_path             data/diverse_human_faces/110/101.cam_default.f_1.info.json\n",
    "    json_path = row['json_path_full']\n",
    "    # json_dest           data/dark_undersampled/110/101.cam_default.f_1.info.json\n",
    "    json_dest = json_path.replace(CURRENT_PATH, DARK_PATH)\n",
    "    shutil.copy2(json_path, json_dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf6004d",
   "metadata": {},
   "source": [
    "Creating the light undersampled dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abf9ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "light_undersampled_df = pd.read_csv('data/light_undersampled.csv')\n",
    "\n",
    "light_undersampled_df = light_undersampled_df.assign(\n",
    "    image_path_full = lambda x: 'data/diverse_human_faces/' + x['human_id'].astype(str) + '/' + x['render_id'].astype(str) + '.cam_default.f_1.rgb.png',\n",
    "    json_path_full = lambda x: 'data/diverse_human_faces/' + x['human_id'].astype(str) + '/' + x['render_id'].astype(str) + '.cam_default.f_1.info.json'\n",
    ")\n",
    "\n",
    "CURRENT_PATH = \"data/diverse_human_faces\"\n",
    "LIGHT_PATH = \"data/light_undersampled\"\n",
    "\n",
    "for index, row in tqdm(light_undersampled_df.iterrows(), total = len(light_undersampled_df)):\n",
    "\n",
    "    # create human_id folders in light_undersampled\n",
    "    for idx in light_undersampled_df['human_id'].unique():\n",
    "        os.makedirs(os.path.join(LIGHT_PATH, str(idx)), exist_ok = True)\n",
    "\n",
    "    # images\n",
    "    image_path = row['image_path_full']\n",
    "    image_dest = image_path.replace(CURRENT_PATH, LIGHT_PATH)\n",
    "    shutil.copy2(image_path, image_dest)\n",
    "\n",
    "    # jsons\n",
    "    json_path = row['json_path_full']\n",
    "    json_dest = json_path.replace(CURRENT_PATH, LIGHT_PATH)\n",
    "    shutil.copy2(json_path, json_dest) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8d6426",
   "metadata": {},
   "source": [
    "If you want to evaluate the numbers of each dataset:\n",
    "\n",
    "```python\n",
    "dark_undersampled = pd.read_csv('../data/dark_undersampled.csv')\n",
    "light_undersampled = pd.read_csv('../data/light_undersampled.csv')\n",
    "\n",
    "counts_dark = dark_undersampled.assign(gender_label = lambda x: np.where(x['sex'] == .0, 'Male', 'Female')).value_counts('gender_label').reset_index(name='count')\n",
    "total_count = counts_dark['count'].sum()\n",
    "counts_dark['proportion'] = counts_dark['count'] / total_count\n",
    "counts_dark.loc['Total'] = ['', total_count, '']\n",
    "\n",
    "counts_light = light_undersampled.assign(gender_label = lambda x: np.where(x['sex'] == .0, 'Male', 'Female')).value_counts('gender_label').reset_index(name='count')\n",
    "total_count_light = counts_light['count'].sum()\n",
    "counts_light['proportion'] = counts_light['count'] / total_count_light\n",
    "counts_light.loc['Total'] = ['', total_count_light, '']\n",
    "\n",
    "comp = pd.concat([\n",
    "    counts_light.set_index('gender_label').rename(columns={'count': 'light_count', 'proportion': 'light_female_proportion'}), \n",
    "    counts_dark.set_index('gender_label').rename(columns={'count': 'dark_count', 'proportion': 'dark_female_proportion'})\n",
    "    ], axis=1, sort=False)\n",
    "\n",
    "comp.rename({'': 'Total'})\n",
    "\n",
    "comp\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
